---
title: "Estimation of Neural Net"
output: html_notebook
---

### Installation von Python und TensorFlow (nur einmalig nötig)
```{r}
#install.packages("reticulate")
library(reticulate)

# Installation von miniconda (falls nicht vorhanden)
#install_miniconda(update=TRUE)

# Anlegen einer speziellen Python Umgebung
#conda_create("r-reticulate")

# Installieren der Pakete in der angelegten Umgebung
#conda_install("r-reticulate", "pandas")
#conda_install("r-reticulate", "numpy")
#conda_install("r-reticulate", "tensorflow")
#conda_install("r-reticulate", "h5py")
 
# Verwenden der speziellen Python Umgebung die zuvor erstellt wurde
use_condaenv("r-reticulate")



```


### Aufruf des Skripts zur Datenaufbereitung
```{r}
source("data_prep.R")

```


### Laden benötigter Packages
```{r}
library(reticulate)
library(ggplot2)
library(Metrics)

```


### Definition des Neuronalen Netzes
```{python}
# Benoetigte Python Libraries einbinden
import numpy as np
import tensorflow as tf
from tensorflow import keras

# Definition der Form des tiefen neuronalen Netzes (Deep Neural Net)
model = tf.keras.Sequential([
  keras.layers.Dense(10, activation='relu', input_shape=[len(r.train_dataset.keys())]),
  keras.layers.Dense(4, activation='relu'),
  keras.layers.Dense(1)
])

# Definition der Kosten-(Loss-)Funktion und der Optimierungsfunktion mit seinen Hyperparametern
model.compile(loss="mse", optimizer=tf.keras.optimizers.Adam(0.001))

# Ausgabe einer Zusammenfassung zur Form des Modells, das geschaetzt wird (nicht notwendig)
#model.summary()


```


### Schätzung des neuronalen Netzes
```{python}
# Schaetzung des Modells
history = model.fit(r.train_dataset, r.train_labels, epochs=150,
                    validation_data = (r.test_dataset, r.test_labels), verbose=0)

# Ggf. Speichern des geschaetzten Modells
model.save("python_model.h5")

```


### Auswertung der Modelloptimierung
```{r}
# Grafische Ausgabe der Modelloptimierung

# create data
data <- data.frame(val_loss = unlist(py$history$history$val_loss),
                  loss = unlist(py$history$history$loss))

# Plot
ggplot(data[-1,]) +
  geom_line( aes(x=1:length(val_loss), y=val_loss, colour = "Validation Loss" )) +
  geom_line( aes(x=1:length(loss), y=loss, colour = "Training Loss" )) +
  scale_colour_manual( values = c("Training Loss"="blue", "Validation Loss"="red") ) +
  labs(title="Loss Function Values During Optimization") +
  xlab("Iteration Number") +
  ylab("Loss") 


```


### (Ggf.) Laden eines gespeicherten Neuronalen Netzes ###
```{python}
model = keras.models.load_model("python_model.h5")

```


### Auswertung der Schätzergebnisse ###
```{r}
# Schätzung der (normierten) Preise für die Trainings- und Testdaten
train_predictions_norm <- py$model$predict(train_dataset)
test_predictions_norm <- py$model$predict(test_dataset)

# Rückberechnung der normierten Preisschätzungen zu den tatsächlichen Preisschätzungen bzw. Preisen
train_predictions <- (train_predictions_norm * norm_values_list$sd[1] ) + norm_values_list$mean[1]
test_predictions <- (test_predictions_norm * norm_values_list$sd[1]) + norm_values_list$mean[1]
# Selektion der zugehörigen tatsächlichen Preise
train_actuals <- umsatzdaten$Umsatz[train_ind]
test_actuals <- umsatzdaten$Umsatz[-train_ind]


# Vergleich der Gütekriterien für die Traingings- und Testdaten
cat(paste0("MAPE on the Training Data:\t", format(mape(train_actuals, train_predictions)*100, digits=3, nsmall=2)))
cat(paste0("\nMAPE on the Validation Data:\t", format(mape(test_actuals, test_predictions)*100, digits=3, nsmall=2)))


```

```{r}

## Grafischer vergleich der vorhergesagten und der tatsächlichen Preise für die Trainings- und Testdaten

# Zusammenstellung der Daten für die Plots
data_train <- data.frame(prediction = train_predictions/1000, actual = train_actuals/1000)
data_test <- data.frame(prediction = test_predictions/1000, actual = test_actuals/1000)

# Plot der Ergebnisse der Trainingsdaten
ggplot(data_train[1:100,]) +
  geom_line( aes(x=1:length(prediction), y=prediction, colour = "Predicted Values" )) +
  geom_line( aes(x=1:length(actual), y=actual, colour = "Actual Values" )) +
  scale_colour_manual( values = c("Predicted Values"="blue", "Actual Values"="red") ) +
  labs(title="Predicted and Actual Values for the Training Data") +
  xlab("Case Number") +
  ylab("Umsatz in Euro") 

# Plot der Ergebnisse der Testdaten
ggplot(data_test[1:100,]) +
  geom_line( aes(x=1:length(prediction), y=prediction, colour = "Predicted Values" )) +
  geom_line( aes(x=1:length(actual), y=actual, colour = "Actual Values" )) +
  scale_colour_manual( values = c("Predicted Values"="blue", "Actual Values"="red") ) +
  labs(title="Predicted and Actual Values for the Test Data") +
  xlab("Case Number") +
  ylab("Umsatz in Euro") 


```

```{r}
# Vorhersage für einen einzelnen Fall
cat(paste0("Vorhergesagter Umsatz:\t", round(test_predictions[100])))
cat(paste0("\nTatsächlicher Umsatz:\t", test_actuals[100]))


```

#MAPE je Warengruppe 
```{r}
# Schätzung der (normierten) Preise für die Trainings- und Testdaten
#listofMAPES <- vector(mode = "list", length = 6)
#hey <- 2.0344163 * norm_values_list$sd[13] + norm_values_list$mean[13]
for (i in (1:6)){
  lap <- paste('Warengruppe_',i, sep = "")
  train_predictions_norm <- py$model$predict(filter(train_dataset, train_dataset[,lap] > 1.0))
  #View(train_predictions_norm)
  test_predictions_norm <- py$model$predict(filter(test_dataset,test_dataset[,lap] > 1.0 ))

# Rückberechnung der normierten Preisschätzungen zu den tatsächlichen Preisschätzungen bzw. Preisen
train_predictions <- (train_predictions_norm * norm_values_list$sd[1] ) + norm_values_list$mean[1]
test_predictions <- (test_predictions_norm * norm_values_list$sd[1]) + norm_values_list$mean[1]
# Selektion der zugehörigen tatsächlichen Preise

train_actuals <- filter(umsatzdaten[train_ind,],Warengruppe == i)
train_actuals <- train_actuals$Umsatz
test_actuals <- filter(umsatzdaten[-train_ind,],Warengruppe == i)
test_actuals <- test_actuals$Umsatz
  
# Vergleich der Gütekriterien für die Traingings- und Testdaten

cat(paste0("\n",lap))
cat(paste0("\nMAPE on the Training Data:\t", format(mape(train_actuals, train_predictions)*100, digits=3, nsmall=2)))
cat(paste0("\nMAPE on the Validation Data:\t", format(mape(test_actuals, test_predictions)*100, digits=3, nsmall=2)))

}


```
# Vorhersage für den 5.Juni 2019 je Warengruppen

```{r}

newdata_pred <- py$model$predict(newdata_dataset)
newdata_predictions <- (newdata_pred * norm_values_list$sd[1]) + norm_values_list$mean[1]



```
